# Task-6-K-Nearest-Neighbors-KNN-Classification

 Objective:

To implement and understand the K-Nearest Neighbors (KNN) algorithm using the Iris dataset, and:

Normalize features

Experiment with different values of K

Evaluate using accuracy and confusion matrix

Visualize decision boundaries


ðŸ“š Dataset Used:

Iris Dataset from sklearn.datasets

Used only the first two features for 2D visualization


ðŸ›  Tools & Libraries:

Python

Scikit-learn

NumPy

Pandas

Matplotlib

Steps Performed:

âœ… 1. Data Loading & Preprocessing

Loaded the Iris dataset using sklearn.datasets.load_iris()

Selected first two features for easy visualization

Split the dataset into training and testing sets

Normalized features using StandardScaler


âœ… 2. Model Training & Evaluation

Trained KNeighborsClassifier for multiple values of K: 1, 3, 5, 7

Evaluated models using:

Accuracy

Confusion Matrix

Plotted confusion matrices for each K


âœ… 3. Decision Boundary Visualization

Visualized the decision boundary for K = 3

Used a meshgrid to classify and plot decision regions

Displayed colored regions indicating how the classifier splits the feature space

ðŸ“ˆ Results

K	Accuracy

1	~0.84
3	~0.93
5	~0.89
7	~0.91

ðŸ–¼ Visuals

Confusion Matrices for K = 1, 3, 5, 7

Decision Boundary plot for K = 3 (using normalized features)
